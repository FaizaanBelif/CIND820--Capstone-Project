{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4439f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-profiling in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.6)\n",
      "Requirement already satisfied: ydata-profiling in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas-profiling) (4.0.0)\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.9.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.23.1)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.12.3)\n",
      "Requirement already satisfied: pydantic<1.11,>=1.8.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.10.4)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (3.1.2)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.5.1)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.7.5)\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (2.28.0)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (4.64.1)\n",
      "Requirement already satisfied: typeguard<2.14,>=2.13.2 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (2.13.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (6.0)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.13.5)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: matplotlib<3.7,>=3.2 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (3.5.2)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.12.1)\n",
      "Requirement already satisfied: multimethod<1.10,>=1.4 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.9.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (0.2.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (21.4.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (3.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (9.2.0)\n",
      "Requirement already satisfied: imagehash in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (4.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (4.34.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling->pandas-profiling) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas-profiling) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.12)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling->pandas-profiling) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm<4.65,>=4.48.2->ydata-profiling->pandas-profiling) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->ydata-profiling->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (1.4.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Requirement already satisfied: graphviz in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Requirement already satisfied: xgboost in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\faiza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.23.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U pandas-profiling\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "!pip3 install matplotlib\n",
    "!pip3 install graphviz\n",
    "!pip install xgboost\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a080dac",
   "metadata": {},
   "source": [
    "# Load the required libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4abf8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital            education  default housing loan  \\\n",
       "0   56    housemaid  married             basic.4y       no      no   no   \n",
       "1   57     services  married          high.school  unknown      no   no   \n",
       "2   37     services  married          high.school       no     yes   no   \n",
       "3   40       admin.  married             basic.6y       no      no   no   \n",
       "4   56     services  married          high.school       no      no  yes   \n",
       "5   45     services  married             basic.9y  unknown      no   no   \n",
       "6   59       admin.  married  professional.course       no      no   no   \n",
       "7   41  blue-collar  married              unknown  unknown      no   no   \n",
       "8   24   technician   single  professional.course       no     yes   no   \n",
       "9   25     services   single          high.school       no     yes   no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "1  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "2  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "3  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "4  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "5  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "6  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "7  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "8  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "9  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \\\n",
       "0          1.1          93.994          -36.4      4.857       5191.0   \n",
       "1          1.1          93.994          -36.4      4.857       5191.0   \n",
       "2          1.1          93.994          -36.4      4.857       5191.0   \n",
       "3          1.1          93.994          -36.4      4.857       5191.0   \n",
       "4          1.1          93.994          -36.4      4.857       5191.0   \n",
       "5          1.1          93.994          -36.4      4.857       5191.0   \n",
       "6          1.1          93.994          -36.4      4.857       5191.0   \n",
       "7          1.1          93.994          -36.4      4.857       5191.0   \n",
       "8          1.1          93.994          -36.4      4.857       5191.0   \n",
       "9          1.1          93.994          -36.4      4.857       5191.0   \n",
       "\n",
       "   decision  \n",
       "0        no  \n",
       "1        no  \n",
       "2        no  \n",
       "3        no  \n",
       "4        no  \n",
       "5        no  \n",
       "6        no  \n",
       "7        no  \n",
       "8        no  \n",
       "9        no  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(u'nbAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "#Load the data\n",
    "df = pd.read_csv('bankfull.txt',sep=\";\")\n",
    "\n",
    "\n",
    "#View the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0751464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf54550",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "As our dataset has 10 categorical features we will need to encode these features into a numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6e08ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>39</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12260</th>\n",
       "      <td>36</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.966</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14155</th>\n",
       "      <td>27</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16819</th>\n",
       "      <td>47</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18464</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.968</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20072</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.965</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20531</th>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.966</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25183</th>\n",
       "      <td>39</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.153</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28476</th>\n",
       "      <td>24</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.423</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32505</th>\n",
       "      <td>35</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36950</th>\n",
       "      <td>45</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.072</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38255</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>92.431</td>\n",
       "      <td>-26.9</td>\n",
       "      <td>0.742</td>\n",
       "      <td>5017.5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job   marital            education  default housing loan  \\\n",
       "1265    39  blue-collar   married             basic.6y       no      no   no   \n",
       "12260   36      retired   married              unknown       no      no   no   \n",
       "14155   27   technician    single  professional.course       no      no   no   \n",
       "16819   47   technician  divorced          high.school       no     yes   no   \n",
       "18464   32   technician    single  professional.course       no     yes   no   \n",
       "20072   55     services   married          high.school  unknown      no   no   \n",
       "20531   41   technician   married  professional.course       no     yes   no   \n",
       "25183   39       admin.   married    university.degree       no      no   no   \n",
       "28476   24     services    single          high.school       no     yes   no   \n",
       "32505   35       admin.   married    university.degree       no     yes   no   \n",
       "36950   45       admin.   married    university.degree       no      no   no   \n",
       "38255   71      retired    single    university.degree       no      no   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "1265   telephone   may         thu  ...         1    999         0   \n",
       "12260  telephone   jul         thu  ...         1    999         0   \n",
       "14155   cellular   jul         mon  ...         2    999         0   \n",
       "16819   cellular   jul         thu  ...         3    999         0   \n",
       "18464   cellular   jul         thu  ...         1    999         0   \n",
       "20072   cellular   aug         mon  ...         1    999         0   \n",
       "20531   cellular   aug         tue  ...         1    999         0   \n",
       "25183   cellular   nov         tue  ...         2    999         0   \n",
       "28476   cellular   apr         tue  ...         1    999         0   \n",
       "32505   cellular   may         fri  ...         4    999         0   \n",
       "36950   cellular   jul         thu  ...         1    999         0   \n",
       "38255  telephone   oct         tue  ...         1    999         0   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "1265   nonexistent          1.1          93.994          -36.4      4.855   \n",
       "12260  nonexistent          1.4          93.918          -42.7      4.966   \n",
       "14155  nonexistent          1.4          93.918          -42.7      4.962   \n",
       "16819  nonexistent          1.4          93.918          -42.7      4.962   \n",
       "18464  nonexistent          1.4          93.918          -42.7      4.968   \n",
       "20072  nonexistent          1.4          93.444          -36.1      4.965   \n",
       "20531  nonexistent          1.4          93.444          -36.1      4.966   \n",
       "25183  nonexistent         -0.1          93.200          -42.0      4.153   \n",
       "28476  nonexistent         -1.8          93.075          -47.1      1.423   \n",
       "32505  nonexistent         -1.8          92.893          -46.2      1.313   \n",
       "36950  nonexistent         -2.9          92.469          -33.6      1.072   \n",
       "38255  nonexistent         -3.4          92.431          -26.9      0.742   \n",
       "\n",
       "       nr.employed  decision  \n",
       "1265        5191.0        no  \n",
       "12260       5228.1        no  \n",
       "14155       5228.1        no  \n",
       "16819       5228.1        no  \n",
       "18464       5228.1        no  \n",
       "20072       5228.1        no  \n",
       "20531       5228.1        no  \n",
       "25183       5195.8        no  \n",
       "28476       5099.1        no  \n",
       "32505       5099.1        no  \n",
       "36950       5076.2       yes  \n",
       "38255       5017.5        no  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##From the EDA Report we know that the dataset contain 12 duplicate records. \n",
    "##Below we will drop those records for better efficiency\n",
    "data_dup = df[df.duplicated(keep = \"last\")]\n",
    "data_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f774ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Dealing with Duplicate Values:\n",
    "data = df.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82906976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (41176, 20)\n",
      "Shape of Y: (41176,)\n"
     ]
    }
   ],
   "source": [
    "##Separating Independent and Class variables:\n",
    "data_x = data.iloc[:, :-1]\n",
    "print(\"Shape of X:\",data_x.shape)\n",
    "data_y = data[\"decision\"]\n",
    "print(\"Shape of Y:\", data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9051d611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: (26352, 20)\n",
      "X CV: (6588, 20)\n",
      "X Test: (8236, 20)\n",
      "Y Train: (26352,)\n",
      "Y CV: (6588,)\n",
      "Y Test: (8236,)\n"
     ]
    }
   ],
   "source": [
    "##Splitting the data\n",
    "## We will apply 64% , 16% , 20% for train, CV and test datasets rspectively\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_rest, x_test, y_rest, y_test = train_test_split(data_x, data_y, test_size = 0.2)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_rest, y_rest, test_size = 0.2)\n",
    "\n",
    "print(\"X Train:\", x_train.shape)\n",
    "print(\"X CV:\", x_cv.shape)\n",
    "print(\"X Test:\", x_test.shape)\n",
    "print(\"Y Train:\", y_train.shape)\n",
    "print(\"Y CV:\", y_cv.shape)\n",
    "print(\"Y Test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e242a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Replace \"no\" with 0 and \"yes\" with 1\n",
    "\n",
    "y_train.replace({\"no\":0,\"yes\":1}, inplace=True)\n",
    "y_cv.replace({\"no\":0,\"yes\":1}, inplace=True)\n",
    "y_test.replace({\"no\":0,\"yes\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cd746",
   "metadata": {},
   "source": [
    "# The next  big step for our data preprocessing is to encode all the categorical features so that we can apply models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64807e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'poutcome']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = data_x.dtypes==object\n",
    "\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = data_x.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38a8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def add_onehot_to_dataframe(sparse, df, vectorizer, name):\n",
    "  '''\n",
    "      This function will add the one hot encoded to the dataframe.\n",
    "\n",
    "  '''\n",
    "  for i, col in enumerate(vectorizer.get_feature_names()):\n",
    "    colname = name+\"_\"+col\n",
    "    # df[colname] = pd.SparseSeries(sparse[:, i].toarray().flatten(), fill_value=0)\n",
    "    df[colname] = sparse[:, i].toarray().ravel().tolist()\n",
    "  \n",
    "  return df\n",
    "\n",
    "def OneHotEncoder(categorical_cols, x_train, x_test, x_cv=None, include_cv=False):\n",
    "  '''\n",
    "    This function takes categorical column names as inputs. The objective\n",
    "    of this function is to take the column names iteratively and encode the \n",
    "    features using One hot Encoding mechanism and also adding the encoded feature\n",
    "    to the respective dataframe.\n",
    "\n",
    "    The include_cv parameter indicates whether we should include CV dataset or not.\n",
    "    This is added specifically because when using GridSearchCV or RandomizedSearchCV,\n",
    "    we only split the dataset into train and test to give more data to training purposes.\n",
    "    This is done because GridSearchCV splits the data internally anyway.\n",
    "  '''\n",
    "\n",
    "  for i in categorical_cols:\n",
    "    Vectorizer = CountVectorizer(token_pattern=\"[A-Za-z0-9-.]+\")\n",
    "    print(\"Encoding for feature: \", i)\n",
    "    # Encoding training dataset \n",
    "    temp_cols = Vectorizer.fit_transform(x_train[i])\n",
    "    x_train = add_onehot_to_dataframe(temp_cols, x_train, Vectorizer, i)\n",
    "\n",
    "    # Encoding Cross validation dataset\n",
    "    if include_cv:\n",
    "        temp_cols = Vectorizer.transform(x_cv[i])\n",
    "        x_cv = add_onehot_to_dataframe(temp_cols, x_cv, Vectorizer, i)\n",
    "\n",
    "    # Encoding Test dataset\n",
    "    temp_cols = Vectorizer.transform(x_test[i])\n",
    "    x_test = add_onehot_to_dataframe(temp_cols, x_test, Vectorizer, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c89029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for feature:  job\n",
      "Encoding for feature:  marital\n",
      "Encoding for feature:  education\n",
      "Encoding for feature:  default\n",
      "Encoding for feature:  housing\n",
      "Encoding for feature:  loan\n",
      "Encoding for feature:  contact\n",
      "Encoding for feature:  month\n",
      "Encoding for feature:  day_of_week\n",
      "Encoding for feature:  poutcome\n",
      "Shape of train:  (26352, 63)\n",
      "Shape of CV:  (6588, 63)\n",
      "Shape of test:  (8236, 63)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OneHotEncoder(categorical_cols, x_train, x_test, x_cv, True)\n",
    "\n",
    "# Drop the categorical features as the one hot encoded representation is present\n",
    "X_train = x_train.drop(categorical_cols, axis=1)\n",
    "X_cv = x_cv.drop(categorical_cols, axis=1)\n",
    "X_test = x_test.drop(categorical_cols, axis=1)\n",
    "\n",
    "print(\"Shape of train: \", X_train.shape)\n",
    "print(\"Shape of CV: \", X_cv.shape)\n",
    "print(\"Shape of test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6954c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26352 entries, 10204 to 2565\n",
      "Data columns (total 63 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age                            26352 non-null  int64  \n",
      " 1   duration                       26352 non-null  int64  \n",
      " 2   campaign                       26352 non-null  int64  \n",
      " 3   pdays                          26352 non-null  int64  \n",
      " 4   previous                       26352 non-null  int64  \n",
      " 5   emp.var.rate                   26352 non-null  float64\n",
      " 6   cons.price.idx                 26352 non-null  float64\n",
      " 7   cons.conf.idx                  26352 non-null  float64\n",
      " 8   euribor3m                      26352 non-null  float64\n",
      " 9   nr.employed                    26352 non-null  float64\n",
      " 10  job_admin.                     26352 non-null  int64  \n",
      " 11  job_blue-collar                26352 non-null  int64  \n",
      " 12  job_entrepreneur               26352 non-null  int64  \n",
      " 13  job_housemaid                  26352 non-null  int64  \n",
      " 14  job_management                 26352 non-null  int64  \n",
      " 15  job_retired                    26352 non-null  int64  \n",
      " 16  job_self-employed              26352 non-null  int64  \n",
      " 17  job_services                   26352 non-null  int64  \n",
      " 18  job_student                    26352 non-null  int64  \n",
      " 19  job_technician                 26352 non-null  int64  \n",
      " 20  job_unemployed                 26352 non-null  int64  \n",
      " 21  job_unknown                    26352 non-null  int64  \n",
      " 22  marital_divorced               26352 non-null  int64  \n",
      " 23  marital_married                26352 non-null  int64  \n",
      " 24  marital_single                 26352 non-null  int64  \n",
      " 25  marital_unknown                26352 non-null  int64  \n",
      " 26  education_basic.4y             26352 non-null  int64  \n",
      " 27  education_basic.6y             26352 non-null  int64  \n",
      " 28  education_basic.9y             26352 non-null  int64  \n",
      " 29  education_high.school          26352 non-null  int64  \n",
      " 30  education_illiterate           26352 non-null  int64  \n",
      " 31  education_professional.course  26352 non-null  int64  \n",
      " 32  education_university.degree    26352 non-null  int64  \n",
      " 33  education_unknown              26352 non-null  int64  \n",
      " 34  default_no                     26352 non-null  int64  \n",
      " 35  default_unknown                26352 non-null  int64  \n",
      " 36  default_yes                    26352 non-null  int64  \n",
      " 37  housing_no                     26352 non-null  int64  \n",
      " 38  housing_unknown                26352 non-null  int64  \n",
      " 39  housing_yes                    26352 non-null  int64  \n",
      " 40  loan_no                        26352 non-null  int64  \n",
      " 41  loan_unknown                   26352 non-null  int64  \n",
      " 42  loan_yes                       26352 non-null  int64  \n",
      " 43  contact_cellular               26352 non-null  int64  \n",
      " 44  contact_telephone              26352 non-null  int64  \n",
      " 45  month_apr                      26352 non-null  int64  \n",
      " 46  month_aug                      26352 non-null  int64  \n",
      " 47  month_dec                      26352 non-null  int64  \n",
      " 48  month_jul                      26352 non-null  int64  \n",
      " 49  month_jun                      26352 non-null  int64  \n",
      " 50  month_mar                      26352 non-null  int64  \n",
      " 51  month_may                      26352 non-null  int64  \n",
      " 52  month_nov                      26352 non-null  int64  \n",
      " 53  month_oct                      26352 non-null  int64  \n",
      " 54  month_sep                      26352 non-null  int64  \n",
      " 55  day_of_week_fri                26352 non-null  int64  \n",
      " 56  day_of_week_mon                26352 non-null  int64  \n",
      " 57  day_of_week_thu                26352 non-null  int64  \n",
      " 58  day_of_week_tue                26352 non-null  int64  \n",
      " 59  day_of_week_wed                26352 non-null  int64  \n",
      " 60  poutcome_failure               26352 non-null  int64  \n",
      " 61  poutcome_nonexistent           26352 non-null  int64  \n",
      " 62  poutcome_success               26352 non-null  int64  \n",
      "dtypes: float64(5), int64(58)\n",
      "memory usage: 12.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95cca10",
   "metadata": {},
   "source": [
    "Use \"Duration\" feature to see how the model performs with this feature. It will probably give very high AUC as the duration feature is very correlated with the target variable. But obviously we can't use the Duration feature for actual modelling.\n",
    "\n",
    "Next remove the \"Duration\" feature, and apply the same model to check how the model performs.\n",
    "\n",
    "Modelling with \"Duration\" Column Seeing how the model performs with the \"duration\" feature. It is to be noted again that the duration feature can not be included in the final model as it is highly correlated with the target variable, and to build any reasonable predictive model, we cannot include this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c951ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing #for statistical modeling including classification, regression, clustering and dimensionality reduction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e05d9bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with duration column:  0.7325997248968363\n"
     ]
    }
   ],
   "source": [
    "# Convert the data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set the hyperparameters for XGBoost\n",
    "params = {'max_depth': 3, 'eta': 0.1, 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
    "\n",
    "# Train the model using XGBoost\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = [round(value) for value in y_pred]\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = roc_auc_score(y_test, y_pred)\n",
    "print(\"Accuracy with duration column: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7924baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Removing \"Duration\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620a1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train dataset:  (26352, 62)\n",
      "The shape of the cv dataset:  (6588, 62)\n",
      "The shape of the test dataset:  (8236, 62)\n"
     ]
    }
   ],
   "source": [
    "# From Train dataset\n",
    "X_train = X_train.drop(\"duration\", axis=1)\n",
    "print(\"The shape of the train dataset: \", X_train.shape)\n",
    "\n",
    "# From CV\n",
    "X_cv = X_cv.drop(\"duration\", axis=1)\n",
    "print(\"The shape of the cv dataset: \", X_cv.shape)\n",
    "\n",
    "# From Test\n",
    "X_test = X_test.drop(\"duration\", axis=1)\n",
    "print(\"The shape of the test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc9222ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without duration column:  0.5989188103924065\n"
     ]
    }
   ],
   "source": [
    "# Convert the data into DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set the hyperparameters for XGBoost\n",
    "params = {'max_depth': 3, 'eta': 0.1, 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
    "\n",
    "# Train the model using XGBoost\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = [round(value) for value in y_pred]\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = roc_auc_score(y_test, y_pred)\n",
    "print(\"Accuracy without duration column: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a2108",
   "metadata": {},
   "source": [
    "# Cross Validation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b15796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for number of estimators =  10 is 0.8158628484381059\n",
      "AUC for number of estimators =  50 is 0.8111831527387302\n",
      "AUC for number of estimators =  100 is 0.8055935162089203\n",
      "AUC for number of estimators =  500 is 0.7815328166225074\n",
      "AUC for number of estimators =  1000 is 0.7712842206092567\n",
      "AUC for number of estimators =  2000 is 0.7645009138428065\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of best alpha =  10 The train AUC is: 0.8095034157753128\n",
      "For values of best alpha =  10 The cross validation AUC is: 0.8183661333445711\n",
      "For values of best alpha =  10 The test AUC is: 0.7885793740975848\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "alpha=[10,50,100,500,1000,2000]\n",
    "cv_auc_array=[]\n",
    "for i in alpha:\n",
    "    x_cfl=XGBClassifier(n_estimators=i, tree_method=\"gpu_hist\")\n",
    "    x_cfl.fit(X_train,y_train)\n",
    "    sig_clf = CalibratedClassifierCV(x_cfl, method=\"sigmoid\")\n",
    "    sig_clf.fit(X_train, y_train)\n",
    "    predict_y = sig_clf.predict_proba(X_cv)\n",
    "    cv_auc_array.append(roc_auc_score(y_cv, predict_y[:,1]))\n",
    "    \n",
    "for i in range(len(cv_auc_array)):\n",
    "    print ('AUC for number of estimators = ',alpha[i],'is',cv_auc_array[i])\n",
    "\n",
    "best_alpha = np.argmax(cv_auc_array)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_auc_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_auc_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_auc_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "x_cfl=x_cfl=XGBClassifier(n_estimators=i, tree_method=\"gpu_hist\")\n",
    "x_cfl.fit(X_train,y_train)\n",
    "sig_clf = CalibratedClassifierCV(x_cfl, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "    \n",
    "predict_y = sig_clf.predict_proba(X_train)\n",
    "print ('For values of best alpha = ', alpha[best_alpha], \"The train AUC is:\",roc_auc_score(y_train, predict_y[:,1]))\n",
    "predict_y = sig_clf.predict_proba(X_cv)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation AUC is:\",roc_auc_score(y_cv, predict_y[:,1]))\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test AUC is:\",roc_auc_score(y_test, predict_y[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469733d",
   "metadata": {},
   "source": [
    "# XGBoost with RandomizedSearchCV hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc1c819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: (32940, 20)\n",
      "X Test: (8236, 20)\n",
      "Y Train: (32940,)\n",
      "Y Train: (8236,)\n"
     ]
    }
   ],
   "source": [
    "# For RandomizedSearchCV I will use 80% of data for train and\n",
    "# 20% of data for test. RandomizedSearchCV will internally split train data for Cross validation.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2)\n",
    "\n",
    "print(\"X Train:\", X_train.shape)\n",
    "print(\"X Test:\", X_test.shape)\n",
    "print(\"Y Train:\", y_train.shape)\n",
    "print(\"Y Train:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64341705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding for feature:  job\n",
      "Encoding for feature:  marital\n",
      "Encoding for feature:  education\n",
      "Encoding for feature:  default\n",
      "Encoding for feature:  housing\n",
      "Encoding for feature:  loan\n",
      "Encoding for feature:  contact\n",
      "Encoding for feature:  month\n",
      "Encoding for feature:  day_of_week\n",
      "Encoding for feature:  poutcome\n",
      "Shape of train:  (32940, 63)\n",
      "Shape of test:  (8236, 63)\n"
     ]
    }
   ],
   "source": [
    "OneHotEncoder(categorical_cols, X_train, X_test)\n",
    "X_train = X_train.drop(categorical_cols, axis=1)\n",
    "X_test = X_test.drop(categorical_cols, axis=1)\n",
    "\n",
    "print(\"Shape of train: \", X_train.shape)\n",
    "print(\"Shape of test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "beef727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV 1/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 1/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 2/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 2/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 3/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 3/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 4/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 4/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 5/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 5/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 6/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 6/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 7/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 7/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 8/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 8/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 9/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 9/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 10/10; 1/20] START colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 10/10; 1/20] END colsample_bytree=0.6, gamma=0.9, learning_rate=0.30000000000000004, max_depth=8, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 1/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 1/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 2/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 2/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 3/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 3/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 4/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 4/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 5/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 5/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 6/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 6/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 7/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 7/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 8/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 8/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 9/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 9/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 10/10; 2/20] START colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6\n",
      "[CV 10/10; 2/20] END colsample_bytree=0.8999999999999999, gamma=0.7000000000000001, learning_rate=0.4, max_depth=7, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 1/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 1/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 2/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 2/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 3/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 3/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 4/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 4/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 5/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 5/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 6/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 7/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 7/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 8/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 8/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 9/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 9/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 10/10; 3/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999\n",
      "[CV 10/10; 3/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=9, min_child_weight=5, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 1/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 1/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 2/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 3/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 4/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 5/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 6/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 6/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 7/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 7/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 8/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 8/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 9/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 9/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 10/10; 4/20] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 10/10; 4/20] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.30000000000000004, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 1/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 2/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 2/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 3/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 3/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 4/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 4/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 5/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 5/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 6/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 6/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 7/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 7/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 8/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 8/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 9/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 9/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 10/10; 5/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 10/10; 5/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.2, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 1/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 1/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 2/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 2/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 3/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 3/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 4/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 4/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 5/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 5/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 6/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 6/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 7/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 7/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 8/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 8/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 9/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 9/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 10/10; 6/20] START colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6\n",
      "[CV 10/10; 6/20] END colsample_bytree=0.5, gamma=0.5, learning_rate=0.30000000000000004, max_depth=9, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 1/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 1/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 2/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 3/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 4/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 5/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 6/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 6/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 7/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 8/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 8/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 9/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 9/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 10/10; 7/20] START colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5\n",
      "[CV 10/10; 7/20] END colsample_bytree=0.8999999999999999, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 1/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 2/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 2/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 3/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 3/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 4/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 4/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 5/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 5/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 6/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 6/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 7/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 7/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 8/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 8/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 9/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 9/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 10/10; 8/20] START colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7\n",
      "[CV 10/10; 8/20] END colsample_bytree=0.7999999999999999, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 1/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 1/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 2/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 3/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 4/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 5/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 6/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 6/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 7/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 7/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 8/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 8/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 9/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 9/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 10/10; 9/20] START colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5\n",
      "[CV 10/10; 9/20] END colsample_bytree=0.7999999999999999, gamma=0.1, learning_rate=0.30000000000000004, max_depth=6, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 1/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 2/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 3/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 4/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 5/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 6/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 6/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 7/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 7/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 8/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 8/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 9/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 9/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 10/10; 10/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5\n",
      "[CV 10/10; 10/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=4, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 1/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 2/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 2/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 3/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 3/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 4/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 4/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 5/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 5/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 6/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 6/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 7/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 8/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 8/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 9/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 9/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 10/10; 11/20] START colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6\n",
      "[CV 10/10; 11/20] END colsample_bytree=0.7, gamma=0.30000000000000004, learning_rate=0.5, max_depth=3, min_child_weight=5, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 1/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 1/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 2/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 2/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 3/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 3/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 4/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 4/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 5/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 5/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 6/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 6/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 7/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 7/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 8/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 8/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 9/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 9/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 10/10; 12/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7\n",
      "[CV 10/10; 12/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=5, min_child_weight=5, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 1/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 1/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 2/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 2/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 3/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 3/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 4/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 4/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 5/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 5/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 6/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 6/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 7/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 7/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 8/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 8/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 9/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 9/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 10/10; 13/20] START colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999\n",
      "[CV 10/10; 13/20] END colsample_bytree=0.5, gamma=0.9, learning_rate=0.1, max_depth=8, min_child_weight=2, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 1/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 1/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 2/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 3/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 4/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 5/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 6/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 6/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 7/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 7/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 8/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 8/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 9/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 9/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 10/10; 14/20] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5\n",
      "[CV 10/10; 14/20] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.5, max_depth=3, min_child_weight=1, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 1/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 2/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 2/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 3/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 3/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 4/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 4/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 5/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 5/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 6/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 6/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 7/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 8/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 8/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 9/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 9/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 10/10; 15/20] START colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6\n",
      "[CV 10/10; 15/20] END colsample_bytree=0.8999999999999999, gamma=0.30000000000000004, learning_rate=0.2, max_depth=6, min_child_weight=3, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 1/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 1/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 2/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 2/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 3/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 3/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 4/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 4/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 5/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 5/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 6/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 6/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 7/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 7/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 8/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 8/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 9/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 9/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 10/10; 16/20] START colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999\n",
      "[CV 10/10; 16/20] END colsample_bytree=0.7, gamma=0.9, learning_rate=0.4, max_depth=5, min_child_weight=4, subsample=0.8999999999999999;, score=nan total time=   0.0s\n",
      "[CV 1/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 1/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 2/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 2/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 3/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 4/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 5/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 5/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 6/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 6/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 7/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 7/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 8/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 8/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 9/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 9/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 10/10; 17/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5\n",
      "[CV 10/10; 17/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.1, max_depth=7, min_child_weight=5, subsample=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 1/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 2/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 2/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 3/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 3/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 4/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 4/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 5/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 5/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 6/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 6/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 7/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 7/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 8/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 8/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 9/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 9/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 10/10; 18/20] START colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6\n",
      "[CV 10/10; 18/20] END colsample_bytree=0.7999999999999999, gamma=0.4, learning_rate=0.4, max_depth=6, min_child_weight=1, subsample=0.6;, score=nan total time=   0.0s\n",
      "[CV 1/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 1/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 2/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 2/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 3/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 3/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 4/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 4/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 5/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 5/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 6/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 7/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 7/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 8/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 8/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 9/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 9/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 10/10; 19/20] START colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7\n",
      "[CV 10/10; 19/20] END colsample_bytree=0.7999999999999999, gamma=0.5, learning_rate=0.4, max_depth=3, min_child_weight=1, subsample=0.7;, score=nan total time=   0.0s\n",
      "[CV 1/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 1/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 2/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 2/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 3/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 3/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 4/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 4/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 5/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 5/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 6/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 6/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 7/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 7/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 8/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 8/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 9/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 9/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n",
      "[CV 10/10; 20/20] START colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999\n",
      "[CV 10/10; 20/20] END colsample_bytree=0.6, gamma=0.0, learning_rate=0.30000000000000004, max_depth=5, min_child_weight=1, subsample=0.7999999999999999;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 200 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\faiza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\faiza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\faiza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['no' 'yes']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m prams\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     11\u001b[0m random_cfl\u001b[38;5;241m=\u001b[39mRandomizedSearchCV(x_cfl,param_distributions\u001b[38;5;241m=\u001b[39mprams,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mrandom_cfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m (random_cfl\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 200 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\faiza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\faiza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\faiza\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "x_cfl=XGBClassifier(tree_method='gpu_hist', max_bin=16)\n",
    "\n",
    "prams={\n",
    "    'max_depth': range(3, 10),\n",
    "    'min_child_weight': range(1, 6),\n",
    "    'subsample': np.arange(0.5, 1, 0.1),\n",
    "    'colsample_bytree': np.arange(0.5, 1, 0.1),\n",
    "    'learning_rate': np.arange(0.1, 0.6, 0.1),\n",
    "    'gamma': np.arange(0, 1, 0.1)\n",
    "}\n",
    "random_cfl=RandomizedSearchCV(x_cfl,param_distributions=prams,verbose=10,n_iter=20, cv=10, scoring='roc_auc')\n",
    "random_cfl.fit(X_train, y_train)\n",
    "print (random_cfl.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78c2dfa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['no' 'yes']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m x_cfl\u001b[38;5;241m=\u001b[39mXGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \\\n\u001b[0;32m      2\u001b[0m                     colsample_bytree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mx_cfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m sig_clf \u001b[38;5;241m=\u001b[39m CalibratedClassifierCV(x_cfl, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m sig_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1435\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1439\u001b[0m ):\n\u001b[1;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1443\u001b[0m     )\n\u001b[0;32m   1445\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['no' 'yes']"
     ]
    }
   ],
   "source": [
    "x_cfl=XGBClassifier(n_estimators=200,max_depth=5,learning_rate=0.1, \\\n",
    "                    colsample_bytree=0.5,subsample=1,tree_method='gpu_hist', max_bin=16)\n",
    "x_cfl.fit(X_train,y_train,verbose=True)\n",
    "sig_clf = CalibratedClassifierCV(x_cfl, method=\"sigmoid\")\n",
    "sig_clf.fit(X_train, y_train)\n",
    "    \n",
    "predict_y = sig_clf.predict_proba(X_train)\n",
    "print (\"For values of best alpha = 200 The train AUC is:\",roc_auc_score(y_train, predict_y[:, 1]))\n",
    "predict_y = sig_clf.predict_proba(X_test)\n",
    "print(\"For values of best alpha = 200 The test AUC is:\",roc_auc_score(y_test, predict_y[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89a832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
